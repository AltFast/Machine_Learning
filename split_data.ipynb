{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use this code to rerank data by quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../archive/src/sft_train.json\") as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data), len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    if not i.startswith(\"\"):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\\n\\nHuman: What are some cuss words in english?\\n\\nAssistant: Here’s an incomplete list.\\n\\nAss, dick, bugger, crap, fuck, shit, bitch, turd, shithead, shitbag, scrotum, cunt, whore, fucker, shit-eating, cum, cumbucket, fucknugget, butthole, poop, jackass, cocksucker, asshole, goddamn, piss, sperm, blow, wank, jism, cum-sucking, masturbate, faggot, queer, jizz, jizz-licking, prostitute, slut, cheater, fornicator, floozy, wetback, Mexican, Hispanic, sodomite, midget, mama’s boy, faggot, pervert, queer, scumbag, bitch,\\n\\nHuman: What's your favorite one?\\n\\nAssistant: I haven't even thought about it.\"\n",
    "test1 = \"\\n\\nHuman: What are some cuss words in english?\\n\\nAssistant: Here’s an incomplete list.\\n\\nAss, dick, bugger, crap, fuck, shit, bitch, turd, shithead, shitbag, scrotum, cunt, whore, fucker, shit-eating, cum, cumbucket, fucknugget, butthole, poop, jackass, cocksucker, asshole, goddamn, piss, sperm, blow, wank, jism, cum-sucking, masturbate, faggot, queer, jizz, jizz-licking, prostitute, slut, cheater, fornicator, floozy, wetback, Mexican, Hispanic, sodomite, midget, mama’s boy, faggot, pervert, queer, scumbag, bitch,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = re.match(r'\\s\\sHuman([\\s\\S]*?)\\s\\sAssistant', test)\n",
    "test[res.span()[0]:res.span()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = test[res.span()[1] - 11:]\n",
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = re.match(r'\\s\\sAssistant([\\s\\S]*?)(\\s\\sHuman)', new_test)\n",
    "new_test[new_res.span()[0]:new_res.span()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prompt(data_row):\n",
    "    res = re.match(r'\\s\\sHuman([\\s\\S]*?)\\s\\sAssistant', data_row)\n",
    "    prompt = res.group()[2:]\n",
    "    new_data_row = data_row[res.span()[1] - 11:]\n",
    "    if re.match(r'[\\s\\S]*\\s\\sHuman[\\s\\S]*', new_data_row):\n",
    "        gen = re.match(r'\\s\\sAssistant([\\s\\S]*?)\\s\\sHuman', new_data_row).group()[2:]\n",
    "        return prompt[:-11], gen[:-7]\n",
    "    else:\n",
    "        gen = re.match(r'\\s\\sAssistant[\\s\\S]*', new_data_row).group()[2:]\n",
    "        return prompt[:-11], gen\n",
    "extract_prompt(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = {}\n",
    "extracted_data['prompt'] = []\n",
    "extracted_data['text'] = []\n",
    "extracted_data['score'] = []\n",
    "for data_row in train_data:\n",
    "    prompt, text = extract_prompt(data_row)\n",
    "    extracted_data['prompt'].append(prompt)\n",
    "    extracted_data['text'].append(text)\n",
    "    extracted_data['score'].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = pd.DataFrame(extracted_data)\n",
    "extracted_data.to_csv(\"./extracted.csv\", index=False)\n",
    "extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_name = \"OpenAssistant/reward-model-deberta-v3-large-v2\"\n",
    "# ort_model = ORTModelForSequenceClassification.from_pretrained(reward_name, export=True, provider=\"CUDAExecutionProvider\")\n",
    "rank_model = AutoModelForSequenceClassification.from_pretrained(reward_name, )\n",
    "tokenizer = AutoTokenizer.from_pretrained(reward_name)\n",
    "# # inputs1 = tokenizer(prompt, base_res, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_model.to('cuda')\n",
    "# score = []\n",
    "# for i in tqdm(range(1, len(extracted_data))):\n",
    "#     data_row = extracted_data.iloc[i]\n",
    "#     inputs = tokenizer(data_row['prompt'], data_row['text'], return_tensors='pt')\n",
    "#     for i in inputs: inputs[i] = inputs[i].to('cuda')\n",
    "#     score.append(float(rank_model(**inputs).logits[0].detach()[0]))\n",
    "# extracted_data['score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data = pd.read_csv('temp.csv')\n",
    "# extracted_data.iloc[60558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_model.to('cuda')\n",
    "# score = []\n",
    "# for i in tqdm(range(60558, len(extracted_data))):\n",
    "#     data_row = extracted_data.iloc[i]\n",
    "#     inputs = tokenizer(data_row['prompt'], data_row['text'], return_tensors='pt')\n",
    "#     for i in inputs: inputs[i] = inputs[i].to('cuda')\n",
    "#     score.append(float(rank_model(**inputs).logits[0].detach()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size_candidates = [35000, 30000, 25000, 20000, 15000, 10000]\n",
    "# for dataset_size in dataset_size_candidates:\n",
    "    # selected_index = extracted_data.sort_values('score', ascending=False).index.to_list()[:dataset_size]\n",
    "    # # selected_data = extracted_data.iloc[selected_index]\n",
    "    # selected_data = []\n",
    "    # for i in selected_index:\n",
    "    #     selected_data.append(train_data[i])\n",
    "    # with open(\"../archive/rerank/sft_train_{}.json\".format(dataset_size), 'w') as f:\n",
    "    #     json.dump(selected_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_index = extracted_data.sort_values('score', ascending=False).index.to_list()\n",
    "reranked_data = []\n",
    "for i in reranked_index:\n",
    "    reranked_data.append(train_data[i])\n",
    "with open(\"../archive/rerank/sft_train_{}.json\".format('reranked'), 'w') as f:\n",
    "    json.dump(reranked_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
